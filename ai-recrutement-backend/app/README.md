
ğŸš€ AI Recruitment â€“ Backend (FastAPI)

Backend du projet AI Recruitment, une plateforme intelligente de recrutement basÃ©e sur lâ€™IA.
Ce backend fournit une API REST sÃ©curisÃ©e pour la gestion des utilisateurs, CV, offres dâ€™emploi et matching.

ğŸ§± Stack Technique

Python 3.10+

FastAPI

PostgreSQL

Docker

SQLAlchemy

JWT (Authentification)

Passlib + bcrypt

ChromaDB (prÃ©vu pour le vector store / IA)

ğŸ“ Structure du projet
ai-recrutement-backend/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                # Point dâ€™entrÃ©e FastAPI
â”‚   â”œâ”€â”€ api/                   # Routes (auth, candidats, offres, etc.)
â”‚   â”œâ”€â”€ core/                  # Config, DB, sÃ©curitÃ©, schÃ©ma SQL
â”‚   â”œâ”€â”€ models/                # ModÃ¨les SQLAlchemy
â”‚   â”œâ”€â”€ schemas/               # SchÃ©mas Pydantic
â”‚   â”œâ”€â”€ services/              # Logique mÃ©tier
â”‚   â”œâ”€â”€ ai/                    # Modules IA (analyse CV, matching)
â”‚   â”œâ”€â”€ vector_store/          # ChromaDB
â”‚   â””â”€â”€ utils/                 # Outils (logging, scoring)
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

âœ… PrÃ©requis

Avant de commencer, assure-toi dâ€™avoir installÃ© :

Python 3.10 ou plus

Docker Desktop (v4.57.0 ou proche)

Git

VÃ©rification :

python --version
docker --version
git --version

ğŸ³ 1. Lancer PostgreSQL avec Docker
1ï¸âƒ£ DÃ©marrer Docker Desktop

Assure-toi que Docker est bien lancÃ© (icÃ´ne verte).

2ï¸âƒ£ CrÃ©er le container PostgreSQL
docker run --name pg-ai \
  -e POSTGRES_PASSWORD=postgres \
  -e POSTGRES_DB=ai_recrutement \
  -p 5432:5432 \
  -d postgres:15


VÃ©rification :

docker ps

ğŸ—„ï¸ 2. Initialiser la base de donnÃ©es

CrÃ©er les tables Ã  partir du schÃ©ma SQL.

Depuis la racine du projet :

type app\core\schema.sql | docker exec -i pg-ai psql -U postgres -d ai_recrutement


VÃ©rifier les tables :

docker exec -it pg-ai psql -U postgres -d ai_recrutement -c "\dt"

ğŸ 3. Installer le backend FastAPI
1ï¸âƒ£ CrÃ©er et activer un environnement virtuel
python -m venv venv
venv\Scripts\activate

2ï¸âƒ£ Installer les dÃ©pendances
pip install -r requirements.txt


âš ï¸ Important (compatibilitÃ© auth) :

pip install bcrypt==4.0.1

âš™ï¸ 4. Configuration .env

CrÃ©er un fichier .env Ã  la racine du projet :

DATABASE_URL=postgresql+psycopg2://postgres:postgres@localhost:5432/ai_recrutement
JWT_SECRET=dev_secret_123
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60
CORS_ORIGINS=http://localhost:8501,http://localhost:3000
APP_NAME=AI Recruitment API
ENV=dev


âš ï¸ Le fichier .env est ignorÃ© par Git.

ğŸš€ 5. Lancer lâ€™API
uvicorn app.main:app --reload


Si tout est correct :

Uvicorn running on http://127.0.0.1:8000

ğŸ§ª 6. Tester lâ€™API (Swagger)
Swagger UI

ğŸ‘‰ http://127.0.0.1:8000/docs

Health check
GET /health


RÃ©ponse attendue :

{ "status": "ok" }

Authentification â€“ ordre recommandÃ©
1ï¸âƒ£ Register
POST /api/auth/register


Body :

{
  "email": "test@example.com",
  "password": "123456",
  "role": "candidat"
}

2ï¸âƒ£ Login
POST /api/auth/login


Copier le access_token.

3ï¸âƒ£ Tester une route protÃ©gÃ©e

Cliquer sur Authorize dans Swagger :

Bearer <ACCESS_TOKEN>


Puis :

GET /api/auth/me

### CV (candidat authentifiÃ©)
- POST /cvs/upload â€” Upload PDF, analyse IA, sauvegarde BDD + index Chroma
- GET /cvs/my-cvs â€” Liste des CVs du candidat
- GET /cvs/{id} â€” DÃ©tail dâ€™un CV
- DELETE /cvs/{id} â€” Supprimer un CV
- POST /cvs/index â€” Indexer un CV dans Chroma
- POST /cvs/search-offres â€” Recherche sÃ©mantique dâ€™offres pour un CV

### Offres
- GET /offres â€” Liste des offres (pagination, filtre statut/localisation), public
- GET /offres/{id} â€” DÃ©tail dâ€™une offre, public
- POST /offres â€” CrÃ©er une offre (recruteur)
- POST /offres/index â€” Indexer une offre dans Chroma
- POST /offres/search-cvs â€” Recherche sÃ©mantique de CVs pour une offre

### Candidats
- GET /candidats/me â€” Profil du candidat connectÃ©
- GET /candidats/me/cvs â€” Liste des CVs du candidat (alias de /cvs/my-cvs)
- GET /candidats/{id}/cvs â€” Liste des CVs (candidat : uniquement les siens si id=me/current)

### Candidatures
- POST /candidatures â€” Postuler (offre_id, cv_id), calcule score + explication IA
- GET /candidatures â€” Mes candidatures (candidat) ou candidatures dâ€™une offre (recruteur, ?offre_id=)
- GET /candidatures/{id} â€” DÃ©tail dâ€™une candidature

### Matching
- POST /matching/score â€” Score 1 CV vs 1 offre (cv_id, offre_id)
- POST /matching/search-offres â€” Meilleures offres pour un CV (cv_id, top_k)
- POST /matching/search-candidats/{offre_id} â€” Meilleurs candidats pour une offre
- POST /matching/match â€” Compat frontend (body: candidate, job)
- POST /matching/test â€” Test avec cv_json et offre_json directs

ğŸ” SÃ©curitÃ©

Hash des mots de passe avec bcrypt

Authentification JWT

RÃ´les : candidat, recruteur, admin

DÃ©pendances FastAPI pour la protection des routes

#pour la partie d'analyse de cv 
 il faut installer  Ã§a "pip install fastapi uvicorn requests python-dotenv PyPDF2 python-multipart langchain langchain-groq "
 pour le fichier json  est dans e dossier cv_extraits
 j'ai   fait un fichier pour tester s'appele test_cv_upload pour le tester il faut  faire :
 1-cd app
 2-python test_cv_upload.py
 puis aller dans le navigateur et taper  http://localhost:8000 puis tester avec un cv sous format pdf



## Vector Store & Recherche SÃ©mantique (Membre 4)

Cette partie du backend implÃ©mente le **vector store** du projet AI Recruitment.
Elle permet dâ€™effectuer une **recherche sÃ©mantique CV â†” Offres** Ã  lâ€™aide dâ€™**embeddings** et de **ChromaDB**, afin de fournir une shortlist pertinente au module de matching.
### Objectifs

* Transformer les **CV** et **offres dâ€™emploi** en reprÃ©sentations vectorielles
* Stocker ces vecteurs dans une base vectorielle persistante
* Rechercher les documents les plus similaires (Top-K)
* Exposer ces fonctionnalitÃ©s via une API FastAPI
* Servir de base au module de **matching & explication** (Membre 5)

### âš™ï¸ Technologies utilisÃ©es

* **ChromaDB** â€“ Base de donnÃ©es vectorielle locale
* **Embeddings ONNX** : `all-MiniLM-L6-v2`
* FastAPI
* Stockage persistant sur disque (pas de dÃ©pendance cloud)

> Aucun appel Ã  une API externe pour les embeddings
> âœ fonctionnement 100 % local


### ğŸ“ Fichiers concernÃ©s

```text
app/vector_store/
 â”œâ”€â”€ chroma_client.py        # Initialisation du client Chroma
 â”œâ”€â”€ text_builders.py        # Conversion JSON â†’ texte
 â”œâ”€â”€ indexing.py             # Indexation et recherche sÃ©mantique
 â””â”€â”€ test_full_pipeline.py   # Test end-to-end sans API
```

Les donnÃ©es vectorielles sont persistÃ©es automatiquement dans :

```text
chroma_data/
```

---

### Configuration (.env)

Ajouter ou vÃ©rifier les variables suivantes :

```env
# --- CHROMA ---
CHROMA_PERSIST_DIR=./chroma_data
CHROMA_COLLECTION_CVS=cvs
CHROMA_COLLECTION_OFFRES=offres
``

### ğŸ“¦ Installation spÃ©cifique

```bash
pip install chromadb
```

âš ï¸ Lors du premier lancement, le modÃ¨le dâ€™embeddings (`~80 MB`) est tÃ©lÃ©chargÃ© automatiquement.

### Lancer lâ€™API

```bash
uvicorn app.main:app --reload --port 8000
```

Documentation Swagger :

```
http://127.0.0.1:8000/docs
```

---

### Endpoints exposÃ©s

#### CVs

* `POST /cvs/index`
  Indexer un CV (JSON analysÃ©)
* `POST /cvs/search-offres`
  Rechercher les offres les plus pertinentes pour un CV

#### Offres

* `POST /offres/index`
  Indexer une offre dâ€™emploi
* `POST /offres/search-cvs`
  Rechercher les CV les plus pertinents pour une offre

---

### ğŸ§ª Test local (sans passer par lâ€™API)

Depuis la racine du projet :

```bash
python -m app.vector_store.test_full_pipeline
```

Ce test :

* indexe plusieurs CV et offres
* gÃ©nÃ¨re les embeddings
* effectue une recherche Top-K
* affiche les rÃ©sultats de similaritÃ©

---

### ğŸ§  Notes techniques

* Les **embeddings** fonctionnent sur du **texte**, pas sur du JSON structurÃ©
  âœ les CV et offres sont convertis en texte avant vectorisation.
* ChromaDB agit comme une **mÃ©moire sÃ©mantique**, pas comme un moteur dâ€™IA gÃ©nÃ©rative.
* Le calcul du score final et lâ€™explication IA sont rÃ©alisÃ©s dans le module de **matching** (Membre 5).


